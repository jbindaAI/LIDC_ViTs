{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76b7613-9740-45b7-9739-2dd1e4ad8989",
   "metadata": {},
   "source": [
    "## Finetuning pre-trained in a self-supervised manner ViT transformer on LIDC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292aebee-36e9-4e91-8d9f-ab85e85d73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from typing import Optional, Dict\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67e7e91-c2ea-4db8-b8fe-4464bf73c380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from my_utils.plot_utils import plot_hists\n",
    "from my_utils.norm_factors import compute_norm_factors\n",
    "from End2End_Model import End2End_Model\n",
    "from LIDC_DataModule import DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff76f4-dbaa-4d90-b3f0-f99fd489fbd1",
   "metadata": {},
   "source": [
    "### Dividing dataset into three sets: training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b091f3ca-054e-4698-b07b-802b6e268fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "local = True\n",
    "if local:\n",
    "    datapath = \"/home/jbinda/INFORM/LIDC/dataset/\"\n",
    "    subsets_saving_path = \"/home/jbinda/INFORM/LIDC_ViTs/dataset/splitted_sets/\"\n",
    "    checkpoints_path=\"/home/jbinda/INFORM/LIDC_ViTs/ckpt/End2End/\"\n",
    "    Path(subsets_saving_path).mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    subsets_saving_path = \"/home/dzban112/LIDC_ViTs/dataset/splitted_sets/\"\n",
    "    Path(subsets_saving_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991502ac-ed27-4e45-a3ae-6cabbc611445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading all annotations and extracting paths, target: benign, malignant.\n",
    "df = pd.read_pickle(f\"{datapath}/ALL_annotations_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ffc878-30f1-4139-b773-c0a8c5dffeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=44)\n",
    "folds = skf.split(X=df[\"path\"], y=df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69db924b-2c3c-476f-bee5-0d01ded31c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_indices, test_indices) in enumerate(folds):\n",
    "    with open(subsets_saving_path+f\"train_fold_{i+1}.pkl\", 'wb') as file:\n",
    "        pickle.dump(list(train_indices), file)\n",
    "    with open(subsets_saving_path+f\"test_fold_{i+1}.pkl\", 'wb') as file:\n",
    "        pickle.dump(list(test_indices), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47f2546-fe6e-4ddc-9a49-e83958fdcf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hists(fold=1, datapath=datapath, subsets_saving_path=subsets_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f49da-e7e2-4094-8d0f-45fd2c516e6d",
   "metadata": {},
   "source": [
    "### Computing Normalization Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5c7927-4e9f-4662-8fca-6038098e423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor(-631.6422), tensor(-631.6422), tensor(-631.6422)], [tensor(360.1392), tensor(360.1392), tensor(360.1392)])\n",
      "([tensor(-627.8815), tensor(-627.8815), tensor(-627.8815)], [tensor(361.9827), tensor(361.9827), tensor(361.9827)])\n",
      "([tensor(-631.6549), tensor(-631.6549), tensor(-631.6549)], [tensor(360.8380), tensor(360.8380), tensor(360.8380)])\n",
      "([tensor(-630.7629), tensor(-630.7629), tensor(-630.7629)], [tensor(358.5543), tensor(358.5543), tensor(358.5543)])\n",
      "([tensor(-630.3823), tensor(-630.3823), tensor(-630.3823)], [tensor(358.9261), tensor(358.9261), tensor(358.9261)])\n",
      "***\n",
      "([tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277), tensor(-635.6277)], [tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904), tensor(366.3904)])\n"
     ]
    }
   ],
   "source": [
    "def prepare_norm_factors(n_splits=5):\n",
    "    df = pd.read_pickle(f\"{datapath}/ALL_annotations_df.pkl\")\n",
    "    fitted_factors_2D = {}\n",
    "    fitted_factors_3D = {}\n",
    "    for fold in range(1, n_splits+1):\n",
    "        # Computing mean and std of image pixels values.\n",
    "        with open(datapath+f\"/splitted_sets/train_fold_{fold}.pkl\", 'rb') as file:\n",
    "            train_indices = pickle.load(file)\n",
    "            X_train = df.iloc[train_indices][\"path\"]\n",
    "            mean2D, std2D = compute_norm_factors(X_train, datapath, full_volume=False)\n",
    "            mean3D, std3D = compute_norm_factors(X_train, datapath, full_volume=True)\n",
    "            \n",
    "            # Creating instance of biomarker scaler\n",
    "            biomarkers = df.iloc[train_indices][[\"subtlety\", \"calcification\",\n",
    "                                                 \"margin\", \"lobulation\",\n",
    "                                                 \"spiculation\", \"diameter\",\n",
    "                                                 \"texture\", \"sphericity\"]].to_numpy() #without targets\n",
    "            scaler = StandardScaler().fit(biomarkers)\n",
    "\n",
    "            # Saving in dictionary object:\n",
    "            fitted_factors_2D[f\"fold_{fold}\"] = (mean2D, std2D, scaler)\n",
    "            fitted_factors_3D[f\"fold_{fold}\"] = (mean3D, std3D, scaler)\n",
    "        \n",
    "\n",
    "    with open(subsets_saving_path+\"/\"+\"fitted_factors_2D.pkl\", 'wb') as f:\n",
    "        pickle.dump(fitted_factors_2D, f)\n",
    "    \n",
    "    with open(subsets_saving_path+\"/\"+\"fitted_factors_3D.pkl\", 'wb') as f:\n",
    "        pickle.dump(fitted_factors_3D, f)\n",
    "    \n",
    "    return fitted_factors_2D, fitted_factors_3D\n",
    "\n",
    "fitted_factors_2D, fitted_factors_3D = prepare_norm_factors(n_splits=5)\n",
    "\n",
    "print(fitted_factors_2D[\"fold_1\"][0:2])\n",
    "print(fitted_factors_2D[\"fold_2\"][0:2])\n",
    "print(fitted_factors_2D[\"fold_3\"][0:2])\n",
    "print(fitted_factors_2D[\"fold_4\"][0:2])\n",
    "print(fitted_factors_2D[\"fold_5\"][0:2])\n",
    "print(\"***\")\n",
    "print(fitted_factors_3D[\"fold_1\"][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3f99c-549f-4586-b5b7-9c2a9ee9966f",
   "metadata": {},
   "source": [
    "## Finetuning End2End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6e7b8-1ac8-4b0e-81be-fa5388257e2c",
   "metadata": {},
   "source": [
    "Finetuning was performed with GPU accelaration. To train model I have used python script `train_End2End.py`.\n",
    "Using first fold I have searched for the best hyperparameters and hyperparameters yielding the best model, were used to train model on five folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467855ac-19bb-4914-9372-e195b2c8c6d0",
   "metadata": {},
   "source": [
    "## End2End model evaluation on validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6664db-8c02-4fbf-a6f8-31ea879b23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2E_model_evaluation(model_name:str, version:Optional[str]=None):\n",
    "    res={}\n",
    "    for fold in range(1,6):\n",
    "        print(f\"fold: {fold}\")\n",
    "        dm = DataModule(\n",
    "            fold=fold,\n",
    "            datapath=datapath,\n",
    "            batch_size=16,\n",
    "            num_workers=8,\n",
    "            task=\"Classification\")\n",
    "\n",
    "        if version is None:\n",
    "            ckpt_path = checkpoints_path+model_name+f\"_{fold}\"+\".ckpt\"\n",
    "        else:\n",
    "            ckpt_path = checkpoints_path+model_name+f\"_{fold}\"+f\"-{version}\"+\".ckpt\"\n",
    "        model = End2End_Model.load_from_checkpoint(ckpt_path)\n",
    "        torch.set_float32_matmul_precision('medium')\n",
    "        trainer = pl.Trainer(accelerator=\"gpu\", devices=1, precision=32)\n",
    "        model.eval()\n",
    "        res[f\"fold_{fold}\"] = trainer.test(model, dm)\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_results(raw_results:Dict[str, list]):\n",
    "    ACC = []\n",
    "    folds = []\n",
    "    mean_ACC = 0\n",
    "    n = 0\n",
    "    for fold in raw_results.keys():\n",
    "        cur_ACC = raw_results[fold][0][\"test_acc\"]\n",
    "        ACC.append(cur_ACC)\n",
    "        folds.append(f\"Fold {fold}\")\n",
    "        mean_ACC += cur_ACC\n",
    "        n += 1\n",
    "    mean_ACC = mean_ACC/n\n",
    "\n",
    "    df = pd.DataFrame({\"Fold\": folds, \"Accuracy\": ACC})\n",
    "    df.loc[len(df)] = ['Mean Accuracy', mean_ACC]\n",
    "    \n",
    "    table = PrettyTable()\n",
    "    table.field_names = df.columns.tolist()\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        table.add_row(row)\n",
    "\n",
    "    # Optionally, align columns\n",
    "    for field in df.columns:\n",
    "        table.align[field] = 'l'  # 'l' for left align, 'r' for right alig\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9061acd-068c-434e-ab71-8577483ce04a",
   "metadata": {},
   "source": [
    "#### DINO_vits16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b63ac3-4890-4dd2-8c84-9bdeb569a8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jbinda/.cache/torch/hub/facebookresearch_dino_main\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/jbinda/INFORM/LIDC_ViTs/lightning_logs\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jbinda/INFORM/LIDC/dataset/splitted_sets/fitted_factors_2D.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dino_vits16_30 - version 0\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mE2E_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdino_vits16_32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mE2E_model_evaluation\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m     18\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 20\u001b[0m     res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:753\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:793\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    795\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:948\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    945\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: preparing data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m--> 948\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_setup_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n\u001b[1;32m    949\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: configuring model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    950\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_configure_model(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:94\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     91\u001b[0m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mbarrier(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpre_setup\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mdatamodule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43m_call_lightning_datamodule_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msetup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m _call_callback_hooks(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n\u001b[1;32m     96\u001b[0m _call_lightning_module_hook(trainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msetup\u001b[39m\u001b[38;5;124m\"\u001b[39m, stage\u001b[38;5;241m=\u001b[39mfn)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:181\u001b[0m, in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningDataModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mdatamodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 181\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/INFORM/LIDC_ViTs/LIDC_DataModule.py:29\u001b[0m, in \u001b[0;36mDataModule.setup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# when model is trained on slices\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatapath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplitted_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfitted_factors_2D.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m         norm_factors \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     31\u001b[0m     mean, std, scaler \u001b[38;5;241m=\u001b[39m norm_factors[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jbinda/INFORM/LIDC/dataset/splitted_sets/fitted_factors_2D.pkl'"
     ]
    }
   ],
   "source": [
    "# dino_vits16_30 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01bd146e-d983-4b43-a4bc-ebdadaf7049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8421052694320679 |\n",
      "| Fold fold_2   | 0.8830409646034241 |\n",
      "| Fold fold_3   | 0.8245614171028137 |\n",
      "| Fold fold_4   | 0.8187134265899658 |\n",
      "| Fold fold_5   | 0.8764705657958984 |\n",
      "| Mean Accuracy | 0.848978328704834  |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065e99f-fa0c-4ebd-a010-6c4f6793abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dino_vits16_30 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_30\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae1acfa-81b0-4fca-a4fc-d4a2958b25a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8421052694320679 |\n",
      "| Fold fold_2   | 0.8538011908531189 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8830409646034241 |\n",
      "| Fold fold_5   | 0.8588235378265381 |\n",
      "| Mean Accuracy | 0.8559752464294433 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc13781-3915-410e-9855-b6b4b9b942ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vits16_30 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_30\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "165f1623-a1dd-457c-99aa-871a01b07090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8245614171028137 |\n",
      "| Fold fold_2   | 0.8421052694320679 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8538011908531189 |\n",
      "| Fold fold_5   | 0.8823529481887817 |\n",
      "| Mean Accuracy | 0.84898521900177   |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fa840-3c50-4ad3-8057-687bd3d55ac0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DINO_vitb16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532e212-a730-47cf-8912-f5d0a014fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef9f331e-7c00-4078-a28d-f283c9f19203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.9005848169326782 |\n",
      "| Fold fold_2   | 0.8538011908531189 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8888888955116272 |\n",
      "| Fold fold_5   | 0.8764705657958984 |\n",
      "| Mean Accuracy | 0.8723701477050781 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14297155-130b-4e38-8f97-ae9bed924bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdace0ad-5abe-49a1-b280-41571948881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8947368264198303 |\n",
      "| Fold fold_2   | 0.871345043182373  |\n",
      "| Fold fold_3   | 0.8538011908531189 |\n",
      "| Fold fold_4   | 0.8888888955116272 |\n",
      "| Fold fold_5   | 0.8941176533699036 |\n",
      "| Mean Accuracy | 0.8805779218673706 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c81b0b-faec-4e7e-a8f6-3346d520a367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8a69e5c-db1a-421f-b6be-25e5c3a445b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8947368264198303 |\n",
      "| Fold fold_2   | 0.8654970526695251 |\n",
      "| Fold fold_3   | 0.847953200340271  |\n",
      "| Fold fold_4   | 0.8830409646034241 |\n",
      "| Fold fold_5   | 0.8823529481887817 |\n",
      "| Mean Accuracy | 0.8747161984443664 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d40ea5-a989-44e0-a703-20ed919d3300",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SL ViTb16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d78513b-5d2c-41c1-9de2-a6acfea678ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ddf79e87da42289a418404e77f1639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# vitb16_31 - version 0\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mE2E_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvit_b_16_6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mE2E_model_evaluation\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m     18\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 20\u001b[0m     res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:753\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:793\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    795\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    314\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:424\u001b[0m, in \u001b[0;36mStrategy.test_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/INFORM/LIDC_ViTs/End2End_Model.py:101\u001b[0m, in \u001b[0;36mEnd2End_Model.test_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    100\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 101\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_hat\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m         y_hat \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/INFORM/LIDC_ViTs/End2End_Model.py:71\u001b[0m, in \u001b[0;36mEnd2End_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_head(x)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:269\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 269\u001b[0m     n, c, h, w \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m    270\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m    271\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_assert(h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image height! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67d27e-0f5b-41db-813f-e6d3a18c3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "715479c8-0864-4d1b-8cee-3b97f2fc6760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f61475644648e8a0ffd011a57f9c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8654970526695251\n",
      "        test_loss           0.2814093828201294\n",
      "\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73503d96949e48fc815e8a0b8d780649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.9064327478408813\n",
      "        test_loss           0.2752917408943176\n",
      "\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b0cb5a03474ab7b343651fe0ac9bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.9005848169326782\n",
      "        test_loss           0.24547657370567322\n",
      "\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffa45a2c7964cc68f3e80695bd00e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8538011908531189\n",
      "        test_loss           0.3516533374786377\n",
      "\n",
      "fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a770020614a36843a203114f23622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8588235378265381\n",
      "        test_loss           0.3135457932949066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76587286-94ba-48aa-921c-d10a9b6392a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8654970526695251 |\n",
      "| Fold fold_2   | 0.9064327478408813 |\n",
      "| Fold fold_3   | 0.9005848169326782 |\n",
      "| Fold fold_4   | 0.8538011908531189 |\n",
      "| Fold fold_5   | 0.8588235378265381 |\n",
      "| Mean Accuracy | 0.8770278692245483 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8cce215-bf98-47e5-8d0a-0fe07d018be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f8f6dfa7e8477683da34853c32addb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8830409646034241\n",
      "        test_loss           0.2770581841468811\n",
      "\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271ddcae87f42f4a00f8c9a3f8a73a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8888888955116272\n",
      "        test_loss           0.3300187587738037\n",
      "\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d131e7531b90484faa85a17aca584899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8538011908531189\n",
      "        test_loss           0.30848434567451477\n",
      "\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f5079582134302b5fcaea5c59efa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8421052694320679\n",
      "        test_loss           0.3487612307071686\n",
      "\n",
      "fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ba525ebd1743028d26524d8605364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8647058606147766\n",
      "        test_loss           0.32205772399902344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cafb213-e456-4d96-bb02-d335423e2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8830409646034241 |\n",
      "| Fold fold_2   | 0.8888888955116272 |\n",
      "| Fold fold_3   | 0.8538011908531189 |\n",
      "| Fold fold_4   | 0.8421052694320679 |\n",
      "| Fold fold_5   | 0.8647058606147766 |\n",
      "| Mean Accuracy | 0.8665084362030029 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda955fa-5cd5-4822-8a75-a367d0506a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f5a764-b5ee-4a73-bff7-b1f09fbc8b73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Finetuning biomarker regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428646fa-6b83-4397-b5a5-7a4e4e4b3237",
   "metadata": {},
   "source": [
    "Fitting standard scaler for concepts z-score normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28bda325-79ef-4164-bf82-1b3f508599f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "with open(subsets_saving_path+\"/\"+\"y_train.pkl\", 'rb') as f:\n",
    "    biomarkers = pickle.load(f).iloc[:, 1:].to_numpy() #without targets\n",
    "\n",
    "SCALER = StandardScaler().fit(biomarkers)\n",
    "with open(subsets_saving_path+\"/\"+\"scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(SCALER, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22709d4-0e53-4ebe-b2a7-7bd301d211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(subsets_saving_path+\"/\"+\"y_train.pkl\", 'rb') as f:\n",
    "    biomarkers = pickle.load(f).iloc[:, 1:] #without targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc182ea-f94f-4fa3-902f-003abea0a98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtlety</th>\n",
       "      <th>calcification</th>\n",
       "      <th>margin</th>\n",
       "      <th>lobulation</th>\n",
       "      <th>spiculation</th>\n",
       "      <th>diameter</th>\n",
       "      <th>texture</th>\n",
       "      <th>sphericity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>9.563974</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6.950641</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>38.389619</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.505375</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.479321</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subtlety  calcification    margin  lobulation  spiculation   diameter  \\\n",
       "739  4.750000       3.750000  4.750000    1.250000     1.250000   9.563974   \n",
       "212  3.666667       5.333333  4.000000    1.666667     1.666667   6.950641   \n",
       "701  5.000000       6.000000  3.000000    2.750000     2.500000  38.389619   \n",
       "453  3.000000       6.000000  3.666667    1.000000     1.000000   7.505375   \n",
       "359  4.000000       4.500000  4.250000    3.000000     1.250000  10.479321   \n",
       "\n",
       "      texture  sphericity  \n",
       "739  5.000000    4.500000  \n",
       "212  5.000000    4.000000  \n",
       "701  3.500000    3.000000  \n",
       "453  2.666667    3.333333  \n",
       "359  5.000000    2.500000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomarkers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb5d6c60-039e-4339-99ed-fe39f646ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.17086039,  5.48092532,  4.08928571,  1.82467532,  1.70941558,\n",
       "       13.31841242,  4.61268939,  3.8045184 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALER.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2c2447-3552-433c-88c3-2d4e28cd3d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53394931,  0.97568008,  0.6879606 ,  0.67164221,  0.79473187,\n",
       "       64.95064945,  0.57377973,  0.42182257])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALER.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c5994-cf24-45df-b0fb-17cd1f12fd44",
   "metadata": {},
   "source": [
    "Finetuning was performed using slurm queuing system on the one GPU. To train model I have used python script `train_biomarker.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abba0a0-185f-4342-b3f3-2c83584fde09",
   "metadata": {},
   "source": [
    "Training was performed with 50 epochs and I tried following sets of key hiperparameters: \n",
    "<br>\n",
    "**1.** **ViT_biom_1**, 10 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**2.** **ViT_biom_2**, 20 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**3.** **ViT_biom_3**, 20 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**4.** **ViT_biom_4**, 30 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**5.** **ViT_biom_5**, 30 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**6.** **ViT_biom_6**, 40 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**7.** **ViT_biom_7**, 40 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**8.** **ViT_biom_8**, 40 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**9.** **ViT_biom_9**, 50 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**10.** **ViT_biom_10**, 50 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**11.** **ViT_biom_11**, 50 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**12.** **ViT_biom_12**, 50 trainable layers, dropout=0.003 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**13.** **ViT_biom_13**, 60 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**14.** **ViT_biom_14**, 60 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**15.** **ViT_biom_15**, 60 trainable layers, dropout=0.003 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524e17f-3a7e-41ce-8b77-40e85722b501",
   "metadata": {},
   "source": [
    "After having look on validation MSE curves I chosen top 5 models with best validation MSE:  \n",
    "**ViT_biom_13**, **ViT_biom_11**, **ViT_biom_10**, **ViT_biom_4**, **ViT_biom_8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba2527-085c-4f5e-bed8-2cfd088c546f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Biomarker Model evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0baef52-00b6-4518-a839-077010cbb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath+\"/splitted_sets\"+\"/\"+\"fitted_mean_std.pkl\", 'rb') as f:\n",
    "    dict_ = pickle.load(f)\n",
    "with open(datapath+\"/splitted_sets\"+\"/\"+\"scaler.pkl\", 'rb') as f:\n",
    "    SCALER = pickle.load(f)\n",
    "    \n",
    "MEAN = dict_[\"mean\"]\n",
    "STD = dict_[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a3866ed-b081-438f-abf4-adf664cc0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biom_model_evaluation(checkpoint_name):\n",
    "    device=\"cuda\"\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=3),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean=MEAN, std=STD),\n",
    "    ])\n",
    "    ds_test = LIDC_Dataset_biom(\n",
    "                    datadir=datapath,\n",
    "                    transform=test_transform,\n",
    "                    label_transform=SCALER,\n",
    "                    mode=\"test\"\n",
    "                )\n",
    "    test_loader = torch.utils.data.DataLoader(ds_test, shuffle=False, batch_size=16, num_workers=8)\n",
    "    model = Biomarker_Model.load_from_checkpoint(f\"checkpoints/Biomarkers/{checkpoint_name}\").to(device)\n",
    "    \n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=1, precision=\"16-mixed\")\n",
    "    model.eval()\n",
    "    res = trainer.test(model, dataloaders=test_loader)\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluation_wrapper_biom(model_nr:int):\n",
    "    MSE = []\n",
    "    for _ in range(10):\n",
    "        res = biom_model_evaluation(f\"best-checkpoint_{model_nr}.ckpt\")\n",
    "        MSE.append(res[0]['test_mse'])\n",
    "    MSE = np.array(MSE)\n",
    "    return np.mean(MSE), np.std(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d8c22-58e6-4fda-85fb-cc3145a1e0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_13\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "207ba3f6-6b46-4bee-959a-de7d94318cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5773425161838531, standard deviation: 0.03359373442852333\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b22cb8-53ee-4a79-8edb-b913b12a7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_11\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31bf82cc-b594-419a-9b68-57891b2b9062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5906020283699036, standard deviation: 0.028045997638796182\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0065772-c7bd-47a3-814b-bbcb5b8902c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_10\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2324330a-e320-45b0-9700-94a393eaa2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.6141557216644287, standard deviation: 0.028909996747307744\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9e6ec-d987-45be-a924-3e6c1f50568a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_4\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e97a192-79d5-4a14-985f-0869465e00d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.623276162147522, standard deviation: 0.023270278423259114\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b268dc8-4a9e-4574-ba9b-7f3cacabb067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_8\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9b9667f-e084-4b12-a432-54409791e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5965319812297821, standard deviation: 0.02622306491194194\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a916db8-0f64-45f1-88e3-3c0d2e6e5255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
