{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b76b7613-9740-45b7-9739-2dd1e4ad8989",
   "metadata": {},
   "source": [
    "## Finetuning pre-trained in a self-supervised manner ViT transformer on LIDC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292aebee-36e9-4e91-8d9f-ab85e85d73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from lightning import Trainer\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from typing import Optional, Dict\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67e7e91-c2ea-4db8-b8fe-4464bf73c380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "from my_utils.plot_utils import plot_hists\n",
    "from my_utils.norm_factors import compute_norm_factors\n",
    "from End2End_Model import End2End_Model\n",
    "from LIDC_DataModule import DataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff76f4-dbaa-4d90-b3f0-f99fd489fbd1",
   "metadata": {},
   "source": [
    "### Dividing dataset into three sets: training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b091f3ca-054e-4698-b07b-802b6e268fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "local = False\n",
    "if local:\n",
    "    datapath = \"/home/jbinda/INFORM/LIDC/dataset/\"\n",
    "    subsets_saving_path = \"/home/jbinda/INFORM/LIDC_ViTs/dataset/splitted_sets/\"\n",
    "    checkpoints_path=\"/home/jbinda/INFORM/LIDC_ViTs/ckpt/End2End/\"\n",
    "    Path(subsets_saving_path).mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    datapath = \"/home/dzban112/LIDC_ViTs/dataset/\"\n",
    "    subsets_saving_path = \"/home/dzban112/LIDC_ViTs/dataset/splitted_sets/\"\n",
    "    checkpoints_path=\"/home/dzban112/LIDC_ViTs/ckpt/End2End/\"\n",
    "    Path(subsets_saving_path).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991502ac-ed27-4e45-a3ae-6cabbc611445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading all annotations and extracting paths, target: benign, malignant.\n",
    "df = pd.read_pickle(f\"{datapath}/ALL_annotations_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ffc878-30f1-4139-b773-c0a8c5dffeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=44)\n",
    "folds = skf.split(X=df[\"path\"], y=df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69db924b-2c3c-476f-bee5-0d01ded31c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_indices, test_indices) in enumerate(folds):\n",
    "    with open(subsets_saving_path+f\"train_fold_{i+1}.pkl\", 'wb') as file:\n",
    "        pickle.dump(list(train_indices), file)\n",
    "    with open(subsets_saving_path+f\"test_fold_{i+1}.pkl\", 'wb') as file:\n",
    "        pickle.dump(list(test_indices), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47f2546-fe6e-4ddc-9a49-e83958fdcf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 750x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hists(fold=1, datapath=datapath, subsets_saving_path=subsets_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f49da-e7e2-4094-8d0f-45fd2c516e6d",
   "metadata": {},
   "source": [
    "### Computing Normalization Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5c7927-4e9f-4662-8fca-6038098e423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(-625.8784), tensor(363.2248))\n",
      "(tensor(-631.0611), tensor(357.2651))\n",
      "(tensor(-629.7866), tensor(362.4995))\n",
      "(tensor(-633.4309), tensor(356.7941))\n",
      "(tensor(-632.3697), tensor(356.8558))\n"
     ]
    }
   ],
   "source": [
    "def prepare_norm_factors(n_splits=5):\n",
    "    df = pd.read_pickle(f\"{datapath}/ALL_annotations_df.pkl\")\n",
    "    fitted_factors = {}\n",
    "    for fold in range(1, n_splits+1):\n",
    "        # Computing mean and std of image pixels values.\n",
    "        with open(datapath+f\"/splitted_sets/train_fold_{fold}.pkl\", 'rb') as file:\n",
    "            train_indices = pickle.load(file)\n",
    "            X_train = df.iloc[train_indices][\"path\"]\n",
    "            mean, std = compute_norm_factors(X_train, datapath)\n",
    "            \n",
    "            # Creating instance of biomarker scaler\n",
    "            biomarkers = df.iloc[train_indices][[\"subtlety\", \"calcification\",\n",
    "                                                 \"margin\", \"lobulation\",\n",
    "                                                 \"spiculation\", \"diameter\",\n",
    "                                                 \"texture\", \"sphericity\"]].to_numpy() #without targets\n",
    "            scaler = StandardScaler().fit(biomarkers)\n",
    "\n",
    "            # Saving in dictionary object:\n",
    "            fitted_factors[f\"fold_{fold}\"] = (mean, std, scaler)\n",
    "        \n",
    "\n",
    "    with open(subsets_saving_path+\"/\"+\"fitted_factors.pkl\", 'wb') as f:\n",
    "        pickle.dump(fitted_factors, f)\n",
    "    \n",
    "    return fitted_factors\n",
    "\n",
    "fitted_factors = prepare_norm_factors(n_splits=5)\n",
    "\n",
    "print(fitted_factors[\"fold_1\"][0:2])\n",
    "print(fitted_factors[\"fold_2\"][0:2])\n",
    "print(fitted_factors[\"fold_3\"][0:2])\n",
    "print(fitted_factors[\"fold_4\"][0:2])\n",
    "print(fitted_factors[\"fold_5\"][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3f99c-549f-4586-b5b7-9c2a9ee9966f",
   "metadata": {},
   "source": [
    "## Finetuning End2End Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df6e7b8-1ac8-4b0e-81be-fa5388257e2c",
   "metadata": {},
   "source": [
    "Finetuning was performed with GPU accelaration. To train model I have used python script `train_End2End.py`.\n",
    "Using first fold I have searched for the best hyperparameters and hyperparameters yielding the best model, were used to train model on five folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467855ac-19bb-4914-9372-e195b2c8c6d0",
   "metadata": {},
   "source": [
    "## End2End model evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e6664db-8c02-4fbf-a6f8-31ea879b23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2E_model_evaluation(model_name:str, version:Optional[str]=None):\n",
    "    res={}\n",
    "    for fold in range(1,6):\n",
    "        print(f\"fold: {fold}\")\n",
    "        dm = DataModule(\n",
    "            fold=fold,\n",
    "            datapath=datapath,\n",
    "            batch_size=16,\n",
    "            num_workers=8,\n",
    "            task=\"Classification\")\n",
    "\n",
    "        if version is None:\n",
    "            ckpt_path = checkpoints_path+model_name+f\"_{fold}\"+\".ckpt\"\n",
    "        else:\n",
    "            ckpt_path = checkpoints_path+model_name+f\"_{fold}\"+f\"-{version}\"+\".ckpt\"\n",
    "        model = End2End_Model.load_from_checkpoint(ckpt_path)\n",
    "        torch.set_float32_matmul_precision('medium')\n",
    "        trainer = pl.Trainer(accelerator=\"gpu\", devices=1, precision=32)\n",
    "        model.eval()\n",
    "        res[f\"fold_{fold}\"] = trainer.test(model, dm)\n",
    "    return res\n",
    "\n",
    "\n",
    "def compute_results(raw_results:Dict[str, list]):\n",
    "    ACC = []\n",
    "    folds = []\n",
    "    mean_ACC = 0\n",
    "    n = 0\n",
    "    for fold in raw_results.keys():\n",
    "        cur_ACC = raw_results[fold][0][\"test_acc\"]\n",
    "        ACC.append(cur_ACC)\n",
    "        folds.append(f\"Fold {fold}\")\n",
    "        mean_ACC += cur_ACC\n",
    "        n += 1\n",
    "    mean_ACC = mean_ACC/n\n",
    "\n",
    "    df = pd.DataFrame({\"Fold\": folds, \"Accuracy\": ACC})\n",
    "    df.loc[len(df)] = ['Mean Accuracy', mean_ACC]\n",
    "    \n",
    "    table = PrettyTable()\n",
    "    table.field_names = df.columns.tolist()\n",
    "\n",
    "    for row in df.itertuples(index=False):\n",
    "        table.add_row(row)\n",
    "\n",
    "    # Optionally, align columns\n",
    "    for field in df.columns:\n",
    "        table.align[field] = 'l'  # 'l' for left align, 'r' for right alig\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9061acd-068c-434e-ab71-8577483ce04a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DINO_vits16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b63ac3-4890-4dd2-8c84-9bdeb569a8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vits16_30 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01bd146e-d983-4b43-a4bc-ebdadaf7049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8421052694320679 |\n",
      "| Fold fold_2   | 0.8830409646034241 |\n",
      "| Fold fold_3   | 0.8245614171028137 |\n",
      "| Fold fold_4   | 0.8187134265899658 |\n",
      "| Fold fold_5   | 0.8764705657958984 |\n",
      "| Mean Accuracy | 0.848978328704834  |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065e99f-fa0c-4ebd-a010-6c4f6793abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dino_vits16_30 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_30\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ae1acfa-81b0-4fca-a4fc-d4a2958b25a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8421052694320679 |\n",
      "| Fold fold_2   | 0.8538011908531189 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8830409646034241 |\n",
      "| Fold fold_5   | 0.8588235378265381 |\n",
      "| Mean Accuracy | 0.8559752464294433 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc13781-3915-410e-9855-b6b4b9b942ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vits16_30 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"dino_vits16_30\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "165f1623-a1dd-457c-99aa-871a01b07090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8245614171028137 |\n",
      "| Fold fold_2   | 0.8421052694320679 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8538011908531189 |\n",
      "| Fold fold_5   | 0.8823529481887817 |\n",
      "| Mean Accuracy | 0.84898521900177   |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fa840-3c50-4ad3-8057-687bd3d55ac0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### DINO_vitb16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3532e212-a730-47cf-8912-f5d0a014fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef9f331e-7c00-4078-a28d-f283c9f19203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.9005848169326782 |\n",
      "| Fold fold_2   | 0.8538011908531189 |\n",
      "| Fold fold_3   | 0.8421052694320679 |\n",
      "| Fold fold_4   | 0.8888888955116272 |\n",
      "| Fold fold_5   | 0.8764705657958984 |\n",
      "| Mean Accuracy | 0.8723701477050781 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14297155-130b-4e38-8f97-ae9bed924bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdace0ad-5abe-49a1-b280-41571948881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8947368264198303 |\n",
      "| Fold fold_2   | 0.871345043182373  |\n",
      "| Fold fold_3   | 0.8538011908531189 |\n",
      "| Fold fold_4   | 0.8888888955116272 |\n",
      "| Fold fold_5   | 0.8941176533699036 |\n",
      "| Mean Accuracy | 0.8805779218673706 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c81b0b-faec-4e7e-a8f6-3346d520a367",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dino_vitb16_31 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"dino_vitb16_31\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e8a69e5c-db1a-421f-b6be-25e5c3a445b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8947368264198303 |\n",
      "| Fold fold_2   | 0.8654970526695251 |\n",
      "| Fold fold_3   | 0.847953200340271  |\n",
      "| Fold fold_4   | 0.8830409646034241 |\n",
      "| Fold fold_5   | 0.8823529481887817 |\n",
      "| Mean Accuracy | 0.8747161984443664 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d40ea5-a989-44e0-a703-20ed919d3300",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SL ViTb16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d78513b-5d2c-41c1-9de2-a6acfea678ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ddf79e87da42289a418404e77f1639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# vitb16_31 - version 0\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mE2E_model_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvit_b_16_6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 20\u001b[0m, in \u001b[0;36mE2E_model_evaluation\u001b[0;34m(model_name, version)\u001b[0m\n\u001b[1;32m     18\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, precision\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 20\u001b[0m     res[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:753\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_test_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:793\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m )\n\u001b[0;32m--> 793\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;66;03m# remove the tensors from the test results\u001b[39;00m\n\u001b[1;32m    795\u001b[0m results \u001b[38;5;241m=\u001b[39m convert_tensors_to_scalars(results)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    314\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:424\u001b[0m, in \u001b[0;36mStrategy.test_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/INFORM/LIDC_ViTs/End2End_Model.py:101\u001b[0m, in \u001b[0;36mEnd2End_Model.test_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    100\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 101\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_hat\u001b[38;5;241m.\u001b[39msize()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m         y_hat \u001b[38;5;241m=\u001b[39m y_hat\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/INFORM/LIDC_ViTs/End2End_Model.py:71\u001b[0m, in \u001b[0;36mEnd2End_Model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_head(x)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_ML/lib/python3.12/site-packages/torchvision/models/vision_transformer.py:269\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 269\u001b[0m     n, c, h, w \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m    270\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m    271\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_assert(h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image height! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version 0\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67d27e-0f5b-41db-813f-e6d3a18c3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "715479c8-0864-4d1b-8cee-3b97f2fc6760",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f61475644648e8a0ffd011a57f9c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8654970526695251\n",
      "        test_loss           0.2814093828201294\n",
      "\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73503d96949e48fc815e8a0b8d780649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.9064327478408813\n",
      "        test_loss           0.2752917408943176\n",
      "\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b0cb5a03474ab7b343651fe0ac9bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.9005848169326782\n",
      "        test_loss           0.24547657370567322\n",
      "\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffa45a2c7964cc68f3e80695bd00e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8538011908531189\n",
      "        test_loss           0.3516533374786377\n",
      "\n",
      "fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9a770020614a36843a203114f23622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8588235378265381\n",
      "        test_loss           0.3135457932949066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version v1\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\", version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76587286-94ba-48aa-921c-d10a9b6392a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8654970526695251 |\n",
      "| Fold fold_2   | 0.9064327478408813 |\n",
      "| Fold fold_3   | 0.9005848169326782 |\n",
      "| Fold fold_4   | 0.8538011908531189 |\n",
      "| Fold fold_5   | 0.8588235378265381 |\n",
      "| Mean Accuracy | 0.8770278692245483 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8cce215-bf98-47e5-8d0a-0fe07d018be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f8f6dfa7e8477683da34853c32addb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8830409646034241\n",
      "        test_loss           0.2770581841468811\n",
      "\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d271ddcae87f42f4a00f8c9a3f8a73a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8888888955116272\n",
      "        test_loss           0.3300187587738037\n",
      "\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d131e7531b90484faa85a17aca584899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8538011908531189\n",
      "        test_loss           0.30848434567451477\n",
      "\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f5079582134302b5fcaea5c59efa3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8421052694320679\n",
      "        test_loss           0.3487612307071686\n",
      "\n",
      "fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ba525ebd1743028d26524d8605364e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                                                        | 0/? [00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "        test_acc            0.8647058606147766\n",
      "        test_loss           0.32205772399902344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# vitb16_31 - version v2\n",
    "res = E2E_model_evaluation(model_name=\"vit_b_16_6\", version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cafb213-e456-4d96-bb02-d335423e2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "| Fold          | Accuracy           |\n",
      "+---------------+--------------------+\n",
      "| Fold fold_1   | 0.8830409646034241 |\n",
      "| Fold fold_2   | 0.8888888955116272 |\n",
      "| Fold fold_3   | 0.8538011908531189 |\n",
      "| Fold fold_4   | 0.8421052694320679 |\n",
      "| Fold fold_5   | 0.8647058606147766 |\n",
      "| Mean Accuracy | 0.8665084362030029 |\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "results = compute_results(res)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda955fa-5cd5-4822-8a75-a367d0506a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06f5a764-b5ee-4a73-bff7-b1f09fbc8b73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Finetuning biomarker regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428646fa-6b83-4397-b5a5-7a4e4e4b3237",
   "metadata": {},
   "source": [
    "Fitting standard scaler for concepts z-score normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28bda325-79ef-4164-bf82-1b3f508599f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "with open(subsets_saving_path+\"/\"+\"y_train.pkl\", 'rb') as f:\n",
    "    biomarkers = pickle.load(f).iloc[:, 1:].to_numpy() #without targets\n",
    "\n",
    "SCALER = StandardScaler().fit(biomarkers)\n",
    "with open(subsets_saving_path+\"/\"+\"scaler.pkl\", 'wb') as f:\n",
    "    pickle.dump(SCALER, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f22709d4-0e53-4ebe-b2a7-7bd301d211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(subsets_saving_path+\"/\"+\"y_train.pkl\", 'rb') as f:\n",
    "    biomarkers = pickle.load(f).iloc[:, 1:] #without targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bc182ea-f94f-4fa3-902f-003abea0a98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subtlety</th>\n",
       "      <th>calcification</th>\n",
       "      <th>margin</th>\n",
       "      <th>lobulation</th>\n",
       "      <th>spiculation</th>\n",
       "      <th>diameter</th>\n",
       "      <th>texture</th>\n",
       "      <th>sphericity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>4.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>9.563974</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3.666667</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>6.950641</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>38.389619</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.505375</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.479321</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     subtlety  calcification    margin  lobulation  spiculation   diameter  \\\n",
       "739  4.750000       3.750000  4.750000    1.250000     1.250000   9.563974   \n",
       "212  3.666667       5.333333  4.000000    1.666667     1.666667   6.950641   \n",
       "701  5.000000       6.000000  3.000000    2.750000     2.500000  38.389619   \n",
       "453  3.000000       6.000000  3.666667    1.000000     1.000000   7.505375   \n",
       "359  4.000000       4.500000  4.250000    3.000000     1.250000  10.479321   \n",
       "\n",
       "      texture  sphericity  \n",
       "739  5.000000    4.500000  \n",
       "212  5.000000    4.000000  \n",
       "701  3.500000    3.000000  \n",
       "453  2.666667    3.333333  \n",
       "359  5.000000    2.500000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomarkers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb5d6c60-039e-4339-99ed-fe39f646ca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.17086039,  5.48092532,  4.08928571,  1.82467532,  1.70941558,\n",
       "       13.31841242,  4.61268939,  3.8045184 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALER.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e2c2447-3552-433c-88c3-2d4e28cd3d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53394931,  0.97568008,  0.6879606 ,  0.67164221,  0.79473187,\n",
       "       64.95064945,  0.57377973,  0.42182257])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCALER.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c5994-cf24-45df-b0fb-17cd1f12fd44",
   "metadata": {},
   "source": [
    "Finetuning was performed using slurm queuing system on the one GPU. To train model I have used python script `train_biomarker.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abba0a0-185f-4342-b3f3-2c83584fde09",
   "metadata": {},
   "source": [
    "Training was performed with 50 epochs and I tried following sets of key hiperparameters: \n",
    "<br>\n",
    "**1.** **ViT_biom_1**, 10 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**2.** **ViT_biom_2**, 20 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**3.** **ViT_biom_3**, 20 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**4.** **ViT_biom_4**, 30 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**5.** **ViT_biom_5**, 30 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**6.** **ViT_biom_6**, 40 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**7.** **ViT_biom_7**, 40 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**8.** **ViT_biom_8**, 40 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$) \n",
    "<br>\n",
    "**9.** **ViT_biom_9**, 50 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**10.** **ViT_biom_10**, 50 trainable layers, dropout=0.01 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**11.** **ViT_biom_11**, 50 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**12.** **ViT_biom_12**, 50 trainable layers, dropout=0.003 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**13.** **ViT_biom_13**, 60 trainable layers, dropout=0.005 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**14.** **ViT_biom_14**, 60 trainable layers, dropout=0.0 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>\n",
    "**15.** **ViT_biom_15**, 60 trainable layers, dropout=0.003 (all dropout layers), lr=3e-4 (exponential decay, $\\beta=0.95$)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8524e17f-3a7e-41ce-8b77-40e85722b501",
   "metadata": {},
   "source": [
    "After having look on validation MSE curves I chosen top 5 models with best validation MSE:  \n",
    "**ViT_biom_13**, **ViT_biom_11**, **ViT_biom_10**, **ViT_biom_4**, **ViT_biom_8**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ba2527-085c-4f5e-bed8-2cfd088c546f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Biomarker Model evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0baef52-00b6-4518-a839-077010cbb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datapath+\"/splitted_sets\"+\"/\"+\"fitted_mean_std.pkl\", 'rb') as f:\n",
    "    dict_ = pickle.load(f)\n",
    "with open(datapath+\"/splitted_sets\"+\"/\"+\"scaler.pkl\", 'rb') as f:\n",
    "    SCALER = pickle.load(f)\n",
    "    \n",
    "MEAN = dict_[\"mean\"]\n",
    "STD = dict_[\"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a3866ed-b081-438f-abf4-adf664cc0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def biom_model_evaluation(checkpoint_name):\n",
    "    device=\"cuda\"\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256, interpolation=3),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.Normalize(mean=MEAN, std=STD),\n",
    "    ])\n",
    "    ds_test = LIDC_Dataset_biom(\n",
    "                    datadir=datapath,\n",
    "                    transform=test_transform,\n",
    "                    label_transform=SCALER,\n",
    "                    mode=\"test\"\n",
    "                )\n",
    "    test_loader = torch.utils.data.DataLoader(ds_test, shuffle=False, batch_size=16, num_workers=8)\n",
    "    model = Biomarker_Model.load_from_checkpoint(f\"checkpoints/Biomarkers/{checkpoint_name}\").to(device)\n",
    "    \n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    trainer = pl.Trainer(accelerator=\"gpu\", devices=1, precision=\"16-mixed\")\n",
    "    model.eval()\n",
    "    res = trainer.test(model, dataloaders=test_loader)\n",
    "    return res\n",
    "\n",
    "\n",
    "def evaluation_wrapper_biom(model_nr:int):\n",
    "    MSE = []\n",
    "    for _ in range(10):\n",
    "        res = biom_model_evaluation(f\"best-checkpoint_{model_nr}.ckpt\")\n",
    "        MSE.append(res[0]['test_mse'])\n",
    "    MSE = np.array(MSE)\n",
    "    return np.mean(MSE), np.std(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d8c22-58e6-4fda-85fb-cc3145a1e0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_13\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "207ba3f6-6b46-4bee-959a-de7d94318cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5773425161838531, standard deviation: 0.03359373442852333\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b22cb8-53ee-4a79-8edb-b913b12a7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_11\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31bf82cc-b594-419a-9b68-57891b2b9062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5906020283699036, standard deviation: 0.028045997638796182\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0065772-c7bd-47a3-814b-bbcb5b8902c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_10\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2324330a-e320-45b0-9700-94a393eaa2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.6141557216644287, standard deviation: 0.028909996747307744\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9e6ec-d987-45be-a924-3e6c1f50568a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_4\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e97a192-79d5-4a14-985f-0869465e00d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.623276162147522, standard deviation: 0.023270278423259114\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b268dc8-4a9e-4574-ba9b-7f3cacabb067",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ViT_biom_8\n",
    "mean_mse, std = evaluation_wrapper_biom(model_nr=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9b9667f-e084-4b12-a432-54409791e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.5965319812297821, standard deviation: 0.02622306491194194\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean MSE: {mean_mse}, standard deviation: {std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a916db8-0f64-45f1-88e3-3c0d2e6e5255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
